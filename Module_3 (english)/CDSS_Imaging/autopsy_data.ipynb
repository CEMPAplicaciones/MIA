{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T15:08:50.237772Z",
     "start_time": "2025-05-07T15:08:50.223910Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "csv = 'PET_AUTOPSY.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "for index_, row_ in df.iterrows():\n",
    "\n",
    "    alz_path = row_['ALZHEIMER PATHOLOGY']\n",
    "    lb_path = row_['LEWY PATHOLOGY']\n",
    "\n",
    "    if alz_path >= 2 and lb_path < 2:\n",
    "        group = 'pure-AD'\n",
    "    elif alz_path < 2 and lb_path >= 2:\n",
    "        group = 'pure-LB'\n",
    "    elif alz_path >= 2 and lb_path >= 2:\n",
    "        group = 'Mixed'\n",
    "    else:\n",
    "        group = 'Negative'\n",
    "\n",
    "    df.loc[index_, 'group'] = group\n",
    "\n",
    "df = df.loc[df['group'] != 'Mixed']\n",
    "df = df.loc[df['group'] != 'Negative']\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:08:54.783859Z",
     "start_time": "2025-05-07T15:08:50.255932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "atlas_path = '/Users/jsilva/repositories/MIA/Module_3 (english)/CDSS_Imaging/cortex_Harvard_Oxford_orig_atlas.nii.gz'\n",
    "atlas_csv = '/Users/jsilva/repositories/MIA/Module_3 (english)/CDSS_Imaging/Harvard_Oxford.csv'\n",
    "\n",
    "patient_path = '/Users/jsilva/data/MIA/Autopsy/'\n",
    "\n",
    "df_atlas = pd.read_csv(atlas_csv)\n",
    "\n",
    "img_atlas = nib.load(atlas_path)\n",
    "data_atlas =img_atlas.get_fdata()\n",
    "\n",
    "for index_, row_ in df.iterrows():\n",
    "\n",
    "    subject_id = row_['SUBJECT_ID']\n",
    "    image_id = row_['FDG_ID']\n",
    "    img_path = join(patient_path, '%s_I%s' % (subject_id,image_id), 'swfdg_normhist.hdr')\n",
    "\n",
    "    img_ = nib.load(img_path)\n",
    "    data_ = img_.get_fdata()\n",
    "\n",
    "    for index_atlas, row_atlas in df_atlas.iterrows():\n",
    "\n",
    "        roi_name = row_atlas['ROI_NAME']\n",
    "        roi_num = row_atlas['ROI_NUM']\n",
    "\n",
    "        indx_roi_ = np.where(data_atlas == roi_num)\n",
    "        mean_value = np.mean(data_[indx_roi_])\n",
    "\n",
    "        df.loc[index_, roi_name] = mean_value\n",
    "\n"
   ],
   "id": "a75d7fdb5583b3bb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:08:54.903777Z",
     "start_time": "2025-05-07T15:08:54.853838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Most significant differences.\n",
    "from scipy.stats import ttest_ind\n",
    "df_ad = df[df['group'] == 'pure-AD']\n",
    "df_lb = df[df['group'] == 'pure-LB']\n",
    "\n",
    "for roi in df.columns[9:]:\n",
    "\n",
    "    t,p = ttest_ind(df_ad[roi], df_lb[roi])\n",
    "    if p < 0.005:\n",
    "        print(roi, round(p,3))\n",
    "    else:\n",
    "        df = df.drop(columns=[roi])"
   ],
   "id": "575fb22b4f47e623",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferior_Temporal_Gyrus_anterior_division 0.001\n",
      "Intracalcarine_Cortex 0.002\n",
      "Supracalcarine_Cortex 0.005\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:34:31.677772Z",
     "start_time": "2025-05-07T15:34:31.654797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.iloc[:,-3:]\n",
    "y = df['group']\n",
    "X"
   ],
   "id": "201331f404b6c792",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Inferior_Temporal_Gyrus_anterior_division  Intracalcarine_Cortex  \\\n",
       "0                                    1.082464               1.806612   \n",
       "1                                    1.251840               1.562329   \n",
       "4                                    1.169544               1.659618   \n",
       "6                                    1.314990               1.516506   \n",
       "9                                    1.059917               1.709761   \n",
       "10                                   1.135093               1.804450   \n",
       "13                                   1.075888               1.817859   \n",
       "14                                   1.185621               1.575078   \n",
       "16                                   1.133862               1.869121   \n",
       "18                                   1.135471               1.708735   \n",
       "20                                   1.248314               1.594903   \n",
       "23                                   1.149632               1.676073   \n",
       "25                                   0.982843               1.626016   \n",
       "28                                   1.078887               1.504337   \n",
       "30                                   1.212089               1.411708   \n",
       "32                                   1.088533               1.646311   \n",
       "33                                   1.000049               1.685638   \n",
       "35                                   1.013544               1.637316   \n",
       "36                                   1.153239               1.610874   \n",
       "38                                   0.977837               1.632646   \n",
       "39                                   1.046470               1.518456   \n",
       "43                                   1.124046               1.220289   \n",
       "45                                   0.933027               1.680284   \n",
       "48                                   1.113120               1.567770   \n",
       "49                                   1.079186               1.652117   \n",
       "50                                   1.089931               1.656943   \n",
       "51                                   1.015362               1.601580   \n",
       "53                                   1.111120               1.700509   \n",
       "56                                   1.005390               1.540148   \n",
       "59                                   1.055372               1.173652   \n",
       "60                                   1.208924               1.283481   \n",
       "65                                   1.106281               1.786129   \n",
       "66                                   1.144079               1.668255   \n",
       "68                                   1.195597               1.503129   \n",
       "71                                   1.136897               1.676535   \n",
       "72                                   1.169016               1.896330   \n",
       "\n",
       "    Supracalcarine_Cortex  \n",
       "0                1.867905  \n",
       "1                1.582445  \n",
       "4                1.659314  \n",
       "6                1.496108  \n",
       "9                1.648271  \n",
       "10               1.632121  \n",
       "13               1.800605  \n",
       "14               1.542219  \n",
       "16               1.797530  \n",
       "18               1.623819  \n",
       "20               1.526457  \n",
       "23               1.528405  \n",
       "25               1.583457  \n",
       "28               1.420763  \n",
       "30               1.395830  \n",
       "32               1.679500  \n",
       "33               1.740354  \n",
       "35               1.625033  \n",
       "36               1.593906  \n",
       "38               1.493315  \n",
       "39               1.521046  \n",
       "43               1.170224  \n",
       "45               1.685837  \n",
       "48               1.519185  \n",
       "49               1.645614  \n",
       "50               1.576173  \n",
       "51               1.526835  \n",
       "53               1.622163  \n",
       "56               1.372856  \n",
       "59               1.248391  \n",
       "60               1.303402  \n",
       "65               1.683421  \n",
       "66               1.742178  \n",
       "68               1.473910  \n",
       "71               1.734103  \n",
       "72               1.857345  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inferior_Temporal_Gyrus_anterior_division</th>\n",
       "      <th>Intracalcarine_Cortex</th>\n",
       "      <th>Supracalcarine_Cortex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.082464</td>\n",
       "      <td>1.806612</td>\n",
       "      <td>1.867905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.251840</td>\n",
       "      <td>1.562329</td>\n",
       "      <td>1.582445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.169544</td>\n",
       "      <td>1.659618</td>\n",
       "      <td>1.659314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.314990</td>\n",
       "      <td>1.516506</td>\n",
       "      <td>1.496108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.059917</td>\n",
       "      <td>1.709761</td>\n",
       "      <td>1.648271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.135093</td>\n",
       "      <td>1.804450</td>\n",
       "      <td>1.632121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.075888</td>\n",
       "      <td>1.817859</td>\n",
       "      <td>1.800605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.185621</td>\n",
       "      <td>1.575078</td>\n",
       "      <td>1.542219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.133862</td>\n",
       "      <td>1.869121</td>\n",
       "      <td>1.797530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.135471</td>\n",
       "      <td>1.708735</td>\n",
       "      <td>1.623819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.248314</td>\n",
       "      <td>1.594903</td>\n",
       "      <td>1.526457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.149632</td>\n",
       "      <td>1.676073</td>\n",
       "      <td>1.528405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.982843</td>\n",
       "      <td>1.626016</td>\n",
       "      <td>1.583457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.078887</td>\n",
       "      <td>1.504337</td>\n",
       "      <td>1.420763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.212089</td>\n",
       "      <td>1.411708</td>\n",
       "      <td>1.395830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.088533</td>\n",
       "      <td>1.646311</td>\n",
       "      <td>1.679500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000049</td>\n",
       "      <td>1.685638</td>\n",
       "      <td>1.740354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.013544</td>\n",
       "      <td>1.637316</td>\n",
       "      <td>1.625033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.153239</td>\n",
       "      <td>1.610874</td>\n",
       "      <td>1.593906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.977837</td>\n",
       "      <td>1.632646</td>\n",
       "      <td>1.493315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.046470</td>\n",
       "      <td>1.518456</td>\n",
       "      <td>1.521046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.124046</td>\n",
       "      <td>1.220289</td>\n",
       "      <td>1.170224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.933027</td>\n",
       "      <td>1.680284</td>\n",
       "      <td>1.685837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.113120</td>\n",
       "      <td>1.567770</td>\n",
       "      <td>1.519185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.079186</td>\n",
       "      <td>1.652117</td>\n",
       "      <td>1.645614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.089931</td>\n",
       "      <td>1.656943</td>\n",
       "      <td>1.576173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.015362</td>\n",
       "      <td>1.601580</td>\n",
       "      <td>1.526835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.111120</td>\n",
       "      <td>1.700509</td>\n",
       "      <td>1.622163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.005390</td>\n",
       "      <td>1.540148</td>\n",
       "      <td>1.372856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.055372</td>\n",
       "      <td>1.173652</td>\n",
       "      <td>1.248391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.208924</td>\n",
       "      <td>1.283481</td>\n",
       "      <td>1.303402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.106281</td>\n",
       "      <td>1.786129</td>\n",
       "      <td>1.683421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.144079</td>\n",
       "      <td>1.668255</td>\n",
       "      <td>1.742178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.195597</td>\n",
       "      <td>1.503129</td>\n",
       "      <td>1.473910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.136897</td>\n",
       "      <td>1.676535</td>\n",
       "      <td>1.734103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.169016</td>\n",
       "      <td>1.896330</td>\n",
       "      <td>1.857345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:30:31.276800Z",
     "start_time": "2025-05-07T15:30:31.263735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10.0, fit_intercept=True, intercept_scaling=1, class_weight=\"balanced\", random_state=None, solver='lbfgs', max_iter=100)\n",
    "\n",
    "model2 = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=\"balanced\", verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "model2.fit(X,y)\n",
    "\n",
    "y_pred = model2.predict(X)\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "accuracy_score = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy = \", round(accuracy_score,2)*100, \" %\")\n",
    "conf_matrix\n",
    "\n",
    "pickle.dump(model, open('pretrained.pkl', 'wb'))\n"
   ],
   "id": "d961d66e02f642d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  89.0  %\n"
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
