{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/Modulo_3/NLP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVHdPxQ2mzJc"
   },
   "source": [
    "We install some dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Er3LAaC_de9Z",
    "outputId": "1e1257fb-2a2b-48f1-b6c8-28900823ff69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tutorial’: File exists\n",
      "fatal: destination path 'scikit-learn' already exists and is not an empty directory.\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!mkdir tutorial\n",
    "!git clone https://github.com/scikit-learn/scikit-learn.git\n",
    "!pip install scikit-learn\n",
    "!cp -r scikit-learn/doc/tutorial/text_analytics/ tutorial\n",
    "!python tutorial/text_analytics/data/twenty_newsgroups/fetch_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxdxM3tam2d_"
   },
   "source": [
    "We download the dataset that we will use in this example. \n",
    "It is a dataset of emails (approximately 12,000 documents in total), almost evenly divided into 20 groups based on the topics they cover. It was originally collected by Ken Lang, likely for his paper \"Newsweeder: Learning to filter netnews.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaOOU0yThwVK",
    "outputId": "6c97a95d-975b-43b3-fe10-6a8ceeadbdc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',shuffle=True)\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-Ibf9SEkl3N",
    "outputId": "565a3107-1266-4f32-8b4e-f06121f82f29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YiX4hTPkoYS",
    "outputId": "276d5b71-dfd3-46af-b88a-7558d987db04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n",
      "comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.graphics\n",
      "sci.space\n",
      "talk.politics.guns\n",
      "sci.med\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "for t in twenty_train.target[:10]:\n",
    "  print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPLB6Pr4k53J",
    "outputId": "2a340259-34e8-4237-ac30-45d95e7fc093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\n",
      "Subject: Re: Shuttle Launch Question\n",
      "Organization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\n",
      "Distribution: sci\n",
      "Lines: 23\n",
      "\n",
      "From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\n",
      ">>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\n",
      ">>>\"Clear caution & warning memory.  Verify no unexpected\n",
      ">>>errors. ...\".  I am wondering what an \"expected error\" might\n",
      ">>>be.  Sorry if this is a really dumb question, but\n",
      "> \n",
      "> Parity errors in memory or previously known conditions that were waivered.\n",
      ">    \"Yes that is an error, but we already knew about it\"\n",
      "> I'd be curious as to what the real meaning of the quote is.\n",
      "> \n",
      "> tom\n",
      "\n",
      "\n",
      "My understanding is that the 'expected errors' are basically\n",
      "known bugs in the warning system software - things are checked\n",
      "that don't have the right values in yet because they aren't\n",
      "set till after launch, and suchlike. Rather than fix the code\n",
      "and possibly introduce new bugs, they just tell the crew\n",
      "'ok, if you see a warning no. 213 before liftoff, ignore it'.\n",
      "\n",
      " - Jonathan\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[4].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUY4B2CZmHSj"
   },
   "source": [
    "Text preprocessing, tokenization, and keyword filtering are included in ‎‎CountVectorizer‎‎, which creates a feature dictionary and transforms the emails into feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1IcAbgEmGBN",
    "outputId": "b26978dd-62bb-44f0-8b1c-015def691f59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBC7fvLYnmhr"
   },
   "source": [
    "Let's check the size of our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSgE1nRKmcoA",
    "outputId": "20c5ddfb-6a16-4f99-c830-a2895a40a1f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckXmYRmFmwmd"
   },
   "source": [
    "Counting occurrences is a good start, but there's an issue: longer documents will have higher average count values than shorter ones, even if they discuss the same topics.\n",
    "\n",
    "To avoid these potential discrepancies, we simply divide the number of occurrences of each word in a document by the total number of words in that document. These new features are called Term Frequencies (tf).\n",
    "\n",
    "Another refinement, besides transforming the values into tf, is to reduce the weights of words that appear in many documents across the corpus, as they are less informative than words occurring in a smaller portion of the corpus.\n",
    "\n",
    "This scaling reduction is called ‎‎tf-idf‎‎, which stands for \"Term Frequency times Inverse Document Frequency.\"\n",
    "\n",
    "Both ‎‎tf‎‎ and ‎‎tf-idf‎‎ can be calculated as follows using ‎‎TfidfTransformer‎‎:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nFMQVy0Wmv3C"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6WF2nGXpeUG"
   },
   "source": [
    "In the example code above, we first use the \"*fit*\" method to train our estimator on the data and, second, the \"*transform*\" method to convert our count matrix into a tf-idf representation. These two steps can be combined to achieve the same final result while avoiding redundant processing. This is done by using the \"*fit_transform*\" method. \n",
    "\n",
    "Exercise: Replace with the \"*fit_transform*\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgYViQgKragf",
    "outputId": "04edae2e-b2b3-4829-88e1-22a67e54ab01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tuoio1urp69F"
   },
   "source": [
    "Now that we have our features, we can train a classifier to try to predict the category of a post. Let's start with a ‎‎naive Bayes classifier, which provides a good baseline for this task. There are several variants of this classifier; the most suitable for word count is the multinomial variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LdbUVaE6psDm"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AzXLVMWqhec"
   },
   "source": [
    "To try to predict the outcome for a new document, we need to extract the features using almost the same feature extraction pipeline as before. The difference is that we call \"*transform*\" instead of \"*fit_transform*\", since the pipeline has already been fitted to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxTyIfRWqzDe",
    "outputId": "80b689e6-737a-4a99-8d65-0d192f63e8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Jesus Loves You. Follow his guidance and you will be able to reach heaven' => soc.religion.christian\n",
      "'Earth is 7 light years away from the sun' => sci.space\n",
      "'You need to ensure that the engine temperature does not reach above 90 degrees' => rec.autos\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['Jesus Loves You. Follow his guidance and you will be able to reach heaven', 'Earth is 7 light years away from the sun','You need to ensure that the engine temperature does not reach above 90 degrees']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "  print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcgF5dn7f2iL"
   },
   "source": [
    "To make the vectorizer => transformer => classifier pipeline easier to work with, there is a ‎‎Pipeline‎‎ class that behaves like a composite classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vs8gS5lqf1bk",
    "outputId": "5a9f7feb-b6c9-43c7-820b-e58bab290a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXNZlDrsea7n"
   },
   "source": [
    "We can use the same dataset to evaluate the predictive accuracy of the model. For this, the dataset reserves a test portion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEr0slHIr6hw",
    "outputId": "f191a182-17b9-4961-9a3c-1e589292f118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test',shuffle=True)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNW8CZEzgIZ-"
   },
   "source": [
    "We achieved an accuracy of around 75%. Let's see if we can do better with a Support Vector Machine (SVM),‎‎ which is widely considered one of the best text classification algorithms (although it is slightly slower than Naive Bayes):‎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6iSo8XeagW-R",
    "outputId": "b1e16dfd-b932-4f9d-9ce3-8c1d7d7d6354"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248805098247477"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42,max_iter=5, tol=None))])\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vd-d5Ixg1rB"
   },
   "source": [
    "We have improved performance by about 5% using an SVM. ‎scikit-learn‎ provides additional utilities for a more detailed performance analysis of the results:‎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHvj1KQhg0b7",
    "outputId": "4545ac00-edf3-4630-ec79-27cada53207e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.71      0.72       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.88      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.90       396\n",
      "         sci.electronics       0.83      0.62      0.71       393\n",
      "                 sci.med       0.87      0.86      0.87       396\n",
      "               sci.space       0.84      0.96      0.90       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.41      0.55       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vli1czrzgjRx",
    "outputId": "13feeb80-82e4-4fd0-d050-cabdcaf176c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism  -  soc.religion.christian = 44\n",
      "comp.graphics  -  comp.os.ms-windows.misc = 21\n",
      "comp.graphics  -  comp.windows.x = 24\n",
      "comp.os.ms-windows.misc  -  comp.sys.ibm.pc.hardware = 21\n",
      "comp.sys.ibm.pc.hardware  -  comp.os.ms-windows.misc = 27\n",
      "comp.sys.ibm.pc.hardware  -  comp.sys.mac.hardware = 26\n",
      "comp.sys.ibm.pc.hardware  -  sci.electronics = 22\n",
      "comp.sys.mac.hardware  -  comp.sys.ibm.pc.hardware = 22\n",
      "comp.windows.x  -  comp.graphics = 32\n",
      "comp.windows.x  -  comp.os.ms-windows.misc = 42\n",
      "rec.sport.baseball  -  rec.sport.hockey = 32\n",
      "sci.electronics  -  comp.sys.ibm.pc.hardware = 22\n",
      "sci.electronics  -  sci.crypt = 30\n",
      "talk.politics.misc  -  talk.politics.guns = 102\n",
      "talk.religion.misc  -  alt.atheism = 45\n",
      "talk.religion.misc  -  soc.religion.christian = 56\n",
      "talk.religion.misc  -  talk.politics.guns = 22\n"
     ]
    }
   ],
   "source": [
    "for i in twenty_train.target_names:\n",
    "  for j in twenty_train.target_names:\n",
    "    if i!=j and metrics.confusion_matrix(twenty_test.target, predicted)[twenty_train.target_names.index(i),twenty_train.target_names.index(j)]>20:\n",
    "      print ('%s  -  %s = %s' % (i,j,metrics.confusion_matrix(twenty_test.target, predicted)[twenty_train.target_names.index(i),twenty_train.target_names.index(j)])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ULwV6xrklU4"
   },
   "source": [
    "We have already encountered some parameters like *use_idf* in the *TfidfTransformer*. Classifiers tend to have many parameters; for example, *MultinomialNB* includes a smoothing parameter *alpha*, and *SGDClassifier* has a penalty parameter *alpha* along with configurable loss and penalty terms in the objective function.\n",
    "\n",
    "We can try optimizing these parameters to improve our classification. Instead of manually tuning the parameters of the various pipeline components, we can perform an exhaustive search for the best parameters across a grid of possible values. For instance, we test all classifiers on words or bigrams, with or without idf, and with a penalty parameter of 0.01 or 0.001 for the linear SVM:\n",
    "\n",
    "Obviously, such an exhaustive search can be computationally expensive. If we have multiple CPU cores, we can instruct the process to test these eight parameter combinations in parallel. By setting the *n_jobs* parameter to -1, grid search will detect how many cores are installed and use all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ar6aR-NClWsh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3)}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data[:1000], twenty_train.target[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15QUorUbm1C4"
   },
   "source": [
    "The ‎best_score_ and best_params_ objects store the best average score and the parameter configuration corresponding to that score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJU9TUNam9U6",
    "outputId": "3264e29c-3f2b-40ec-d87b-07537d51d290"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.766"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOrf9GOG92JXSXHbtrng7gd",
   "include_colab_link": true,
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
