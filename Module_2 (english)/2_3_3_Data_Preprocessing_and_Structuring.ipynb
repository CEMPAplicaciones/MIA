{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/Modulo_2/2_3_3_Preprocesado_y_estructuracion_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Odb472Qgpsya"
   },
   "source": [
    "# Topic 2.3.3: Data Preprocessing and Structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6vpwGFiK-Xg"
   },
   "source": [
    "Mounting Access to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOus_kzNLJBS",
    "outputId": "0a5d3c93-53ce-403e-b076-c9f55cbb0daf"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mw6BpBaFL8-Z"
   },
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pls9f-Zbp4D_"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OeSAI713nfVN",
    "outputId": "f7e51678-4313-448c-eb7c-c959d4be8ed3"
   },
   "outputs": [],
   "source": [
    "console.rule(\"Data Cleaning\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Documentos/Master IA/Datasets/stroke-data.csv\")\n",
    "console.log(df)\n",
    "\n",
    "# Check for any NaN values\n",
    "nans = df.isnull().values.any()\n",
    "print(\"\\n - Are there any NaN values in the dataset:\", nans)\n",
    "print(\"\\n - Show NaN values by row/column: \\n\", df.isna())\n",
    "\n",
    "# Select rows that contain any NaN values\n",
    "df_n = df[df.isna().any(axis=1)]\n",
    "print(\"\\n - Rows with NaNs:\\n\", df_n)\n",
    "\n",
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "nans = df.isnull().values.any()\n",
    "print(\"\\n - Are there any NaN values in the dataset: \\n\", nans)\n",
    "print(\"\\n - Cleaned dataset: \\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeRheKQO6Sgb"
   },
   "source": [
    "## Data Transformation\n",
    "\n",
    "The `MinMaxScaler` function from the Scikit-learn (sklearn) library is a preprocessing technique used to scale the feature values of a dataset to a specific range. The idea behind MinMaxScaler is to transform the data so that all feature values fall within the specified range, typically (0, 1), although other ranges can also be specified.\n",
    "\n",
    "The formula used to scale the data with MinMaxScaler is as follows:\n",
    "\n",
    "```\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "```\n",
    "\n",
    "where:\n",
    "- `X` is the original value of a feature.\n",
    "- `X_min` is the minimum value of that feature in the dataset.\n",
    "- `X_max` is the maximum value of that feature in the dataset.\n",
    "\n",
    "MinMaxScaler is useful when we want to bring all features of our data to the same scale, which can be beneficial for certain machine learning algorithms that are sensitive to feature scales, such as gradient descent or distance-based algorithms (k-NN, SVM, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE6S1_VA6YIn",
    "outputId": "1bc1b4d9-6cbd-4f00-a17e-c586d084b41f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Select columns with numerical values of interest\n",
    "columns_to_scale = ['age', 'avg_glucose_level', 'bmi']\n",
    "df_s = df[columns_to_scale]\n",
    "\n",
    "# Print the original data\n",
    "print(\" => Original Data: \\n\", df_s.head())\n",
    "\n",
    "# Apply the scaling function\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_s), columns=columns_to_scale)\n",
    "\n",
    "# Print the scaled data\n",
    "print(\" => Scaled Data: \\n\", df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "YHyiDLCVJdz9",
    "outputId": "24621fd5-2196-4690-8694-cadd45a9c156"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "df_norm = (df_scaled - df_scaled.mean()) / df_scaled.std()\n",
    "\n",
    "# Visualize the result\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(1, figsize=(12, 5))\n",
    "\n",
    "# Original data\n",
    "plt.subplot(131)\n",
    "plt.hist(df['bmi'].values, bins=20, color='blue', alpha=0.7)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "# Scaled data\n",
    "plt.subplot(132)\n",
    "plt.hist(df_scaled['bmi'].values, bins=20, color='green', alpha=0.7)\n",
    "plt.title(\"Scaled\")\n",
    "\n",
    "# Normalized data\n",
    "plt.subplot(133)\n",
    "plt.hist(df_norm['bmi'].values, bins=20, color='orange', alpha=0.7)\n",
    "plt.title(\"Normalized\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJdelFQANaBY"
   },
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYBZI9yyNfWs",
    "outputId": "3e0610d6-3168-4dd7-c27b-ed7e1f4ed135"
   },
   "outputs": [],
   "source": [
    "# Example of one-hot encoding with pandas\n",
    "df = df[['id', 'age', 'bmi', 'gender']]\n",
    "cod_gen = pd.get_dummies(df, prefix='gender')\n",
    "print(cod_gen.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd1Ye8cbM2L6"
   },
   "source": [
    "## Encoding Categorical Variables\n",
    "\n",
    "* **LabelBinarizer**: This is a Scikit-learn class used to binarize labels (categories) in a categorical variable. In other words, it converts a categorical variable into a binary representation (0 or 1). When you use `fit_transform()` on a column of a DataFrame, it converts the categories into binary columns where each column represents a category and has a value of 1 if the row belongs to that category and 0 if it does not.\n",
    "  In the example code, we applied `LabelBinarizer` to the 'gender' column of a sample DataFrame, where 'Male' and 'Female' are the categories. The result is a binary matrix where each row represents a 'gender' value, and there are two columns: one for 'Male' and one for 'Female'.\n",
    "\n",
    "* **OneHotEncoder**: This is used to convert categorical variables into a format called \"one-hot encoding\" or \"one-out-of-N encoding.\" This means that each category is represented by a binary matrix where only one value is 1, and the rest are 0.\n",
    "  In the example code, we first applied `LabelBinarizer` to obtain a binary matrix and then used `OneHotEncoder` to convert that matrix into a \"one-hot encoding\" format. The result is a matrix with one column for each category, and each row contains a 1 in the column corresponding to the category and 0 in all other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdjQWMkXOucV",
    "outputId": "739ff61f-0170-4427-d622-3e7c1f60bce2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "\n",
    "# Example of a Test DataFrame\n",
    "data = pd.DataFrame({'gender': ['Male', 'Female', 'Female', 'Male', 'Male']})\n",
    "\n",
    "# LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "data_lb = label_binarizer.fit_transform(data['gender'])\n",
    "print(\"LabelBinarizer Output:\\n\", data_lb)\n",
    "\n",
    "# OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder()\n",
    "data_ohe = onehot_encoder.fit_transform(data_lb)\n",
    "print(\"OneHotEncoder Output:\\n\", data_ohe.toarray())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfd0wX2+R6j/JHb9StBAnF",
   "include_colab_link": true,
   "mount_file_id": "https://github.com/txusser/Master_IA_Sanidad/blob/main/Modulo_2/2_3_3_Preprocesado_y_estructuracion_de_datos.ipynb",
   "name": "2_3_3_Preprocesado_y_estructuracion_de_datos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
