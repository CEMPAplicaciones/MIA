{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/Modulo_2/2_3_4_Modelado_y_evaluaci%C3%B3n_de_resultados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqOg0hOsEdKk"
   },
   "source": [
    "## Modeling and Performance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-oPvQcXEbrE"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich.console import Console\n",
    "console = Console()\n",
    "\n",
    "# Visualization setup\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_palette(\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz4fEtTcEj7j"
   },
   "outputs": [],
   "source": [
    "# We will work with the diabetes dataset from Scikit-learn\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Convert the target into a binary classification problem\n",
    "# Consider values above the median as \"diabetes positive\"\n",
    "y_binary = (y > np.median(y)).astype(int)\n",
    "\n",
    "# Create a DataFrame with feature names\n",
    "feature_names = diabetes.feature_names\n",
    "data = pd.DataFrame(X, columns=feature_names)\n",
    "data['diabetes'] = y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DJz8q3PSsfZL",
    "outputId": "59be63bb-8a12-4f65-a656-6647fbd0060c"
   },
   "outputs": [],
   "source": [
    "# Create a figure with subplots for the boxplots\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Number of features\n",
    "n_features = len(feature_names)\n",
    "rows = (n_features + 1) // 2\n",
    "cols = 2\n",
    "\n",
    "# Create boxplots for each feature\n",
    "for i, feature in enumerate(feature_names, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.boxplot(x='diabetes', y=feature, data=data)\n",
    "    plt.title(f'Distribution of {feature} by Class')\n",
    "    plt.xlabel('Diabetes (0=Negative, 1=Positive)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "ZzLmlpsetmxB",
    "outputId": "44574b7e-866e-47ce-ae01-43984b7ed228"
   },
   "outputs": [],
   "source": [
    "# Display class balance\n",
    "class_balance = data['diabetes'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=class_balance.index, y=class_balance.values)\n",
    "plt.title('Class Balance in the Dataset')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "\n",
    "# Add percentage labels on the bars\n",
    "for i, v in enumerate(class_balance.values):\n",
    "    plt.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EKqGEsDTs6Rc",
    "outputId": "96c09fe3-597b-4670-fcfd-b06cef0d79fd"
   },
   "outputs": [],
   "source": [
    "# Print class balance statistics\n",
    "print(\"\\nClass Balance Statistics:\")\n",
    "print(f\"Class 0 (Negative): {class_balance[0]:.1f}%\")\n",
    "print(f\"Class 1 (Positive): {class_balance[1]:.1f}%\")\n",
    "\n",
    "# Calculate and display descriptive statistics by class\n",
    "print(\"\\nDescriptive Statistics by Class:\")\n",
    "for feature in feature_names:\n",
    "    console.rule(f\"{feature.upper()}\")\n",
    "    print(data.groupby('diabetes')[feature].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nCK5W8WJDWaw",
    "outputId": "ba57a4cf-d0b9-4a63-c02c-26e5cc1580a9"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def visualize_train_test_split(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of training and testing sets,\n",
    "    including set sizes and class distributions.\n",
    "\n",
    "    Args:\n",
    "    X_train, X_test, y_train, y_test: Split datasets\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    # Textual information\n",
    "    print(\"Dataset Shapes:\")\n",
    "    print(f\" - X_train: {X_train.shape}\")\n",
    "    print(f\" - X_test: {X_test.shape}\")\n",
    "    print(f\" - y_train: {y_train.shape}\")\n",
    "    print(f\" - y_test: {y_test.shape}\")\n",
    "\n",
    "    # Set sizes\n",
    "    sizes = {\n",
    "        'Train': X_train.shape[0],\n",
    "        'Test': X_test.shape[0]\n",
    "    }\n",
    "\n",
    "    # Class distribution\n",
    "    train_class_dist = np.bincount(y_train)\n",
    "    test_class_dist = np.bincount(y_test)\n",
    "\n",
    "    # Bar plot for set sizes\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x=list(sizes.keys()), y=list(sizes.values()))\n",
    "    plt.title('Set Sizes')\n",
    "    plt.ylabel('Number of Instances')\n",
    "\n",
    "    # Pie chart for Train/Test proportion\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.pie(sizes.values(), labels=sizes.keys(), autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Train/Test Proportion')\n",
    "\n",
    "    # Pie chart for class distribution in Train\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.pie(train_class_dist, labels=[f'Class {i}' for i in range(len(train_class_dist))],\n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Class Distribution in Train')\n",
    "\n",
    "    # Pie chart for class distribution in Test\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.pie(test_class_dist, labels=[f'Class {i}' for i in range(len(test_class_dist))],\n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Class Distribution in Test')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Additional information\n",
    "    print(\"\\nStatistics:\")\n",
    "    print(f\"Train/Test Ratio: {sizes['Train'] / (sizes['Train'] + sizes['Test']):.2f}\")\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for i in range(len(train_class_dist)):\n",
    "        print(f\"Class {i}:\")\n",
    "        print(f\" - Train: {train_class_dist[i]} ({train_class_dist[i]/sum(train_class_dist)*100:.1f}%)\")\n",
    "        print(f\" - Test: {test_class_dist[i]} ({test_class_dist[i]/sum(test_class_dist)*100:.1f}%)\")\n",
    "\n",
    "# Visualize the training and testing split\n",
    "visualize_train_test_split(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DWDihIJ8IEzF",
    "outputId": "516b1c56-1011-4757-9ec4-cd27081d3fbc"
   },
   "outputs": [],
   "source": [
    "def visualize_train_test_distributions_for_features(X_train, X_test, feature_names):\n",
    "    \"\"\"\n",
    "    Visualizes the distribution of features in the training and testing sets.\n",
    "\n",
    "    Args:\n",
    "    X_train (numpy.ndarray): Training dataset\n",
    "    X_test (numpy.ndarray): Testing dataset\n",
    "    feature_names (list): List of feature names\n",
    "    \"\"\"\n",
    "    n_features = X_train.shape[1]\n",
    "    n_rows = (n_features + 1) // 2  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=(15, 4 * n_rows))\n",
    "    fig.suptitle('Feature Distributions in Training and Testing Sets', fontsize=16)\n",
    "\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        ax = axes[row, col] if n_rows > 1 else axes[col]\n",
    "\n",
    "        sns.kdeplot(X_train[:, i], ax=ax, label='Train', fill=True)\n",
    "        sns.kdeplot(X_test[:, i], ax=ax, label='Test', fill=True)\n",
    "\n",
    "        ax.set_title(f'Distribution of {feature}')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "\n",
    "    # If the number of features is odd, remove the last empty subplot\n",
    "    if n_features % 2 != 0:\n",
    "        fig.delaxes(axes[-1, -1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  # Adjust space for the main title\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize the feature distributions\n",
    "visualize_train_test_distributions_for_features(X_train, X_test, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "XLfy88ytFTF3",
    "outputId": "360e4211-15c6-41ed-9cd9-60e2fa67fa87"
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Diabetes')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "id": "zzWJNQXDFR5j",
    "outputId": "6aa39d1b-160e-4c75-b3b9-d6ba4386d0df"
   },
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and visualize the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Diabetes Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muTe0dvzFgKE",
    "outputId": "bb78f4d4-bf25-4dc9-b661-63e9c81b62f8"
   },
   "outputs": [],
   "source": [
    "# Calculate specific metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"F1-Score: {f1_score:.2f}\")\n",
    "\n",
    "print(f\"- The model correctly identifies {sensitivity*100:.1f}% of positive diabetes cases (sensitivity).\")\n",
    "print(f\"- Of the cases predicted as diabetes positive by the model, {precision*100:.1f}% are actually positive (precision).\")\n",
    "print(f\"- The model correctly identifies {specificity*100:.1f}% of negative diabetes cases (specificity).\")\n",
    "print(f\"- The F1-Score of {f1_score:.2f} indicates a balance between precision and sensitivity.\")\n",
    "print(f\"- The AUC-ROC of {roc_auc:.2f} suggests the model's discriminative capability for diabetes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBcMh2syLG0-"
   },
   "source": [
    "# Interpretation of Results:\n",
    "* The model correctly identifies 67.5% of positive diabetes cases (sensitivity).\n",
    "* Of the cases predicted as diabetes positive, 69.2% are actually positive (precision).\n",
    "* The model correctly identifies 75.5% of negative diabetes cases (specificity).\n",
    "* The F1-Score of 0.68 indicates a balance between precision and sensitivity.\n",
    "* The AUC-ROC of 0.81 suggests a good, though not excellent, discriminative capability for diabetes prediction.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "1. **Overall Performance**:\n",
    "   - The model demonstrates moderate performance in predicting diabetes, with an AUC-ROC of 0.81 indicating a good discriminative capability.\n",
    "\n",
    "2. **Balance Between Sensitivity and Specificity**:\n",
    "   - Sensitivity (67.5%) and specificity (75.5%) are relatively balanced, with a slight inclination towards correctly identifying negative cases.\n",
    "   - This balance suggests the model is somewhat conservative in predicting positive cases.\n",
    "\n",
    "3. **F1-Score**:\n",
    "   - The F1-Score of 0.68 confirms a reasonable balance between precision and sensitivity, though there is room for improvement.\n",
    "\n",
    "## Suggestions for Improvement\n",
    "\n",
    "1. **Threshold Adjustment**:\n",
    "   - Experiment with different classification thresholds to achieve a better trade-off between sensitivity and specificity, especially if prioritizing the detection of positive cases.\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Create new features or transform existing ones to better capture predictive patterns for diabetes.\n",
    "\n",
    "3. **Data Augmentation**:\n",
    "   - If the dataset is small, consider data augmentation techniques to enhance model generalization.\n",
    "\n",
    "4. **Class Imbalance Handling**:\n",
    "   - If there is significant class imbalance, consider using techniques such as SMOTE to oversample the minority class.\n",
    "\n",
    "5. **Cross-Validation**:\n",
    "   - Use cross-validation to obtain a more robust estimate of model performance and avoid overfitting.\n",
    "\n",
    "6. **Domain Knowledge Integration**:\n",
    "   - Consult diabetes experts to incorporate domain-specific knowledge in feature selection and creation.\n",
    "\n",
    "7. **Error Analysis**:\n",
    "   - Conduct a detailed analysis of misclassified cases to identify patterns or subgroups where the model underperforms.\n",
    "\n",
    "8. **Collect More Data**:\n",
    "   - If feasible, collect more data or incorporate additional data sources to enrich the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "YFAt_h2AGIda",
    "outputId": "fbc1b0c5-5640-400c-fc12-fa1a6d6eea85"
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance in Diabetes Prediction')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40rL0GYJGSu-"
   },
   "source": [
    "# Probability Distribution Analysis:\n",
    "The distribution of predicted probabilities can help understand how the model is classifying cases. A bimodal distribution could indicate good separation between classes. If the distribution is skewed towards one end, it may be necessary to adjust the classification threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "tJU05pk8Fi4W",
    "outputId": "9169532c-fdcd-4af3-8da1-ccbc61127b7b"
   },
   "outputs": [],
   "source": [
    "# Additional Analysis: Predicted Probability Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_pred_proba, bins=30, kde=True)\n",
    "plt.title('Predicted Probability Distribution for Diabetes')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFEN9Ct8F1m-"
   },
   "source": [
    "Final Comment on Interpretation in the Context of Diabetes:\n",
    "\n",
    "- Sensitivity is crucial for correctly identifying patients at risk of diabetes.\n",
    "- Specificity helps avoid false positives that could lead to unnecessary tests or treatments.\n",
    "- The balance between sensitivity and specificity should be adjusted based on the consequences of false positives versus false negatives in the context of diabetes.\n",
    "- Feature importance can guide medical professionals on which factors are most relevant to diabetes risk, aiding in the prevention and management of the disease.\n",
    "- This model could serve as an initial screening tool but should not replace professional medical diagnosis.\n",
    "- Given the critical nature of diabetes detection, the model could be adjusted to prioritize higher sensitivity, accepting a possible increase in false positives that can be ruled out through follow-up examinations.\n",
    "\n",
    "Finally: It is crucial to validate any model improvements (updates) using independent test data and, ultimately, in a real clinical environment before deployment.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqE55+MysO1ULofPG/KiCc",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
